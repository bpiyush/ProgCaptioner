{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc2ecf1-afcc-45b8-aa08-78578571c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTHONPATH=\"/athenahomes/piyush/projects/ProgCaptioner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "159086e9-ea79-4479-aff2-5b9edca540dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import torchvideotransforms. Proceeding without.\n",
      "Please install using:\n",
      "pip install git+https://github.com/hassony2/torch_videovision\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/athenahomes/piyush/projects/ProgCaptioner\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "import shared.utils as su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a47cade-c5c9-4829-997f-cb7fa051753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path: str) -> dict:\n",
    "    \"\"\"Helper to load json file\"\"\"\n",
    "    with open(path, 'rb') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7073c374-3110-4f2d-aa2b-61796d4dbe18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load json file\n",
    "out_dir = \"/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/\"\n",
    "json_file = os.path.join(out_dir, \"output_data_utd_test.json\")\n",
    "data = load_json(json_file)\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39474b43-667e-4ee8-b0e7-2a4eba1f0ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame000.png',\n",
       " '/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame037.png',\n",
       " '/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame075.png',\n",
       " '/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame112.png',\n",
       " '/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame150.png',\n",
       " '/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame187.png',\n",
       " '/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame225.png',\n",
       " '/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame262.png']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[\"image_files\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8de1f750-2f8a-4556-bec3-096e0a625692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video9327\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2618b5f309f2409683761b5be2c7f6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01@\\x00\\x00\\x00\\xf0\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load images\n",
    "item = data[np.random.randint(len(data))]\n",
    "images = item[\"image_files\"]\n",
    "images = [PIL.Image.open(f) for f in images]\n",
    "# captions = item[\"response0\"].split(\"\\n\")\n",
    "\n",
    "try:\n",
    "    captions = item['response0'].split(\"\\n\\n\")\n",
    "    assert len(captions) == len(images)\n",
    "except:\n",
    "    captions = item['response0'].split(\"\\n\")\n",
    "    assert len(captions) == len(images)\n",
    "\n",
    "print(item[\"idx\"].split(\"/\")[1])\n",
    "# su.visualize.show_grid_of_images(images, n_cols=len(images), figsize=(14, 4), subtitles=captions)\n",
    "su.visualize.display_frames_with_captions(images, captions, max_width=960)\n",
    "\n",
    "# su.visualize.display_frames_vertical_with_captions(images, captions, max_width=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90927033-2202-4033-b75f-142aeaf290cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 'all/video8317',\n",
       " 'n_frames': 8,\n",
       " 'image_files': ['/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame000.png',\n",
       "  '/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame037.png',\n",
       "  '/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame075.png',\n",
       "  '/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame112.png',\n",
       "  '/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame150.png',\n",
       "  '/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame187.png',\n",
       "  '/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame225.png',\n",
       "  '/scratch/shared/beegfs/piyush/datasets/MSRVTT/progress_captions/frames/all/video8317/frame262.png'],\n",
       " 'query0': \"These are 8 frames extracted from a video sequence depicting woman talking, provide a description for each frame.\\nRequirement: (1) Ensure each frame's description is specific to the corresponding frame, not referencing to other frames; (2) The description should focus on the specific action being performed, capturing the action and progression of the action. There is no need to comment on other elements, such as the background or unrelated objects.\\nReply with the following format:\\n<Frame 1>: Your description\\n...\\n<Frame 8>: Your description\\n\",\n",
       " 'response0': '<Frame 1>: A woman is seen holding a pair of red and yellow threads, possibly for embroidery or sewing. She is wearing a beige cardigan over a pink dress with a golden design on it.\\n<Frame 2>: The woman is now seen applying a red substance to her forehead, which appears to be a traditional bindi, often worn in South Asian cultures.\\n<Frame 3>: The woman is seated and talking, gesturing with her hands as she speaks. She is wearing the same beige cardigan and pink dress with a golden design.\\n<Frame 4>: The woman continues to talk while gesturing with her hands. Her expression suggests she is explaining something.\\n<Frame 5>: The woman is still seated and talking, maintaining her hand gestures. The background includes a logo that reads \"CHAMP UNIVERSITY.\"\\n<Frame 6>: The woman is shown again seated and talking, with the same background and attire.\\n<Frame 7>: The woman is now wearing a blue saree with a red border and a red blouse. She is seated and talking, with the same background and logo.\\n<Frame 8>: The video concludes with a blank screen, indicating the end of the segment.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b33485d-94a9-4aa8-afee-9f48fe1c459a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0 12.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07ce6a5ded548e29d8ea3802c45b2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Sample video'), Output()))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import decord\n",
    "video_path = os.path.join(out_dir, \"../videos\", item['idx'] + \".mp4\")\n",
    "vr = decord.VideoReader(video_path)\n",
    "fps = vr.get_avg_fps()\n",
    "dur = len(vr) / fps\n",
    "\n",
    "print(fps, dur)\n",
    "\n",
    "su.visualize.show_single_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47927859-76b0-45f7-bbf3-bb9bb597c40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e60c670b8148d7a7a100a32fe0b59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01@\\x00\\x00\\x00\\xf0\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "su.visualize.display_frames_vertical_with_captions(images, captions, max_width=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea84330-d350-4937-9e7c-c4a53bc75435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a8cabe-6e3a-49f7-96ac-afdf8ee23ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b640ab4d-21cf-4f39-9105-2bae277d9ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7739c5-3d8a-4649-8908-dce06921fa26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2704d97-b822-4946-8ea2-7e9334d2e6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
